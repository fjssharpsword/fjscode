{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import sys\n",
    "from gym.envs.toy_text import discrete\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, theta=0.0001, discount_factor=1.0):\n",
    "    \"\"\"\n",
    "    Value Iteration Algorithm.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI env. env.P represents the transition probabilities of the environment.\n",
    "            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
    "            env.nS is a number of states in the environment. \n",
    "            env.nA is a number of actions in the environment.\n",
    "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (policy, V) of the optimal policy and the optimal value function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def one_step_lookahead(state, V):\n",
    "        \"\"\"\n",
    "        Helper function to calculate the value for all action in a given state.\n",
    "        \n",
    "        Args:\n",
    "            state: The state to consider (int)\n",
    "            V: The value to use as an estimator, Vector of length env.nS\n",
    "        \n",
    "        Returns:\n",
    "            A vector of length env.nA containing the expected value of each action.\n",
    "        \"\"\"\n",
    "        A = np.zeros(env.nA)\n",
    "        for a in range(env.nA):\n",
    "            for prob, next_state, reward, done in env.P[state][a]:\n",
    "                A[a] += prob * (reward + discount_factor * V[next_state])\n",
    "        return A\n",
    "    \n",
    "    V = np.zeros(env.nS)\n",
    "    while True:\n",
    "        # Stopping condition\n",
    "        delta = 0\n",
    "        # Update each state...\n",
    "        for s in range(env.nS):\n",
    "            # Do a one-step lookahead to find the best action\n",
    "            A = one_step_lookahead(s, V)\n",
    "            best_action_value = np.max(A)\n",
    "            # Calculate delta across all states seen so far\n",
    "            delta = max(delta, np.abs(best_action_value - V[s]))\n",
    "            # Update the value function. Ref: Sutton book eq. 4.10. \n",
    "            V[s] = best_action_value        \n",
    "        # Check if we can stop \n",
    "        if delta < theta:\n",
    "            break\n",
    "    \n",
    "    # Create a deterministic policy using the optimal value function\n",
    "    policy = np.zeros([env.nS, env.nA])\n",
    "    for s in range(env.nS):\n",
    "        # One step lookahead to find the best action for this state\n",
    "        A = one_step_lookahead(s, V)\n",
    "        best_action = np.argmax(A)\n",
    "        # Always take the best action\n",
    "        policy[s, best_action] = 1.0\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "\n",
    "class GridworldEnv(discrete.DiscreteEnv):\n",
    "    \"\"\"\n",
    "    Grid World environment from Sutton's Reinforcement Learning book chapter 4.\n",
    "    You are an agent on an MxN grid and your goal is to reach the terminal\n",
    "    state at the top left or the bottom right corner.\n",
    "\n",
    "    For example, a 4x4 grid looks as follows:\n",
    "\n",
    "    T  o  o  o\n",
    "    o  x  o  o\n",
    "    o  o  o  o\n",
    "    o  o  o  T\n",
    "\n",
    "    x is your position and T are the two terminal states.\n",
    "\n",
    "    You can take actions in each direction (UP=0, RIGHT=1, DOWN=2, LEFT=3).\n",
    "    Actions going off the edge leave you in your current state.\n",
    "    You receive a reward of -1 at each step until you reach a terminal state.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {'render.modes': ['human', 'ansi']}\n",
    "\n",
    "    def __init__(self, shape=[20,20]):\n",
    "        if not isinstance(shape, (list, tuple)) or not len(shape) == 2:\n",
    "            raise ValueError('shape argument must be a list/tuple of length 2')\n",
    "\n",
    "        self.shape = shape\n",
    "\n",
    "        nS = np.prod(shape) #state\n",
    "        nA = 4 #action\n",
    "\n",
    "        MAX_Y = shape[0]\n",
    "        MAX_X = shape[1]\n",
    "\n",
    "        map_matrix = np.load('lab11_map_matrix.npy')\n",
    "        start_s = [] #start point\n",
    "        target_s = [] #target point\n",
    "        obstacle_s= [] #obstacle point\n",
    "        for x in range(map_matrix.shape[0]):\n",
    "            for y in range(map_matrix.shape[1]):\n",
    "                if (map_matrix[x,y]==np.array([255,0,0])).all(): #red\n",
    "                    target_s.append(x*20+y)\n",
    "                elif (map_matrix[x,y]==np.array([255,255,255])).all():#white\n",
    "                    start_s.append(x*20+y)\n",
    "                elif (map_matrix[x,y]==np.array([0,30,0])).all():#green\n",
    "                    obstacle_s.append(x*20+y)\n",
    "                else:\n",
    "                    continue\n",
    "        #reward_matrix = np.load('lab11_reward_matrix.npy')#reward\n",
    "        \n",
    "        P = {}\n",
    "        grid = np.arange(nS).reshape(shape)\n",
    "        it = np.nditer(grid, flags=['multi_index'])\n",
    "\n",
    "        while not it.finished:\n",
    "            s = it.iterindex\n",
    "            y, x = it.multi_index\n",
    "\n",
    "            P[s] = {a : [] for a in range(nA)}\n",
    "\n",
    "            is_done = lambda s: 1 if s in target_s else 0\n",
    "            #is_done = lambda s: s==0 or s==nS-1\n",
    "            if is_done(s):\n",
    "                reward =0.0\n",
    "            elif s in obstacle_s:\n",
    "                reward = -2.0\n",
    "            else:\n",
    "                reward = -1.0\n",
    "\n",
    "            # We're stuck in a terminal state\n",
    "            if is_done(s):\n",
    "                P[s][UP] = [(1, s, reward, True)]\n",
    "                P[s][RIGHT] = [(1, s, reward, True)]\n",
    "                P[s][DOWN] = [(1, s, reward, True)]\n",
    "                P[s][LEFT] = [(1, s, reward, True)]\n",
    "            # Not a terminal state\n",
    "            else:\n",
    "                ns_up = s if y == 0 else s - MAX_X\n",
    "                ns_right = s if x == (MAX_X - 1) else s + 1\n",
    "                ns_down = s if y == (MAX_Y - 1) else s + MAX_X\n",
    "                ns_left = s if x == 0 else s - 1\n",
    "                P[s][UP] = [(1, ns_up, reward, is_done(ns_up))]\n",
    "                P[s][RIGHT] = [(1, ns_right, reward, is_done(ns_right))]\n",
    "                P[s][DOWN] = [(1, ns_down, reward, is_done(ns_down))]\n",
    "                P[s][LEFT] = [(1, ns_left, reward, is_done(ns_left))]\n",
    "\n",
    "            it.iternext()\n",
    "\n",
    "        # Initial state distribution is uniform\n",
    "        isd = np.ones(nS) / nS\n",
    "\n",
    "        # We expose the model of the environment for educational purposes\n",
    "        # This should not be used in any model-free learning algorithm\n",
    "        self.P = P\n",
    "        \n",
    "        super(GridworldEnv, self).__init__(nS, nA, P, isd)\n",
    "\n",
    "    def _render(self, mode='human', close=False):\n",
    "        if close:\n",
    "            return\n",
    "\n",
    "        outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
    "\n",
    "        grid = np.arange(self.nS).reshape(self.shape)\n",
    "        it = np.nditer(grid, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            s = it.iterindex\n",
    "            y, x = it.multi_index\n",
    "\n",
    "            if self.s == s:\n",
    "                output = \" x \"\n",
    "            elif s == 0 or s == self.nS - 1:\n",
    "                output = \" T \"\n",
    "            else:\n",
    "                output = \" o \"\n",
    "\n",
    "            if x == 0:\n",
    "                output = output.lstrip() \n",
    "            if x == self.shape[1] - 1:\n",
    "                output = output.rstrip()\n",
    "\n",
    "            outfile.write(output)\n",
    "\n",
    "            if x == self.shape[1] - 1:\n",
    "                outfile.write(\"\\n\")\n",
    "\n",
    "            it.iternext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Grid Policy (0=up, 1=right, 2=down, 3=left):\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2]\n",
      " [1 1 1 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      " [1 1 2 1 2 2 2 2 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      " [2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      " [1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 0 0 3 3 3]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 3 3 3]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "(2,3)\n",
      "(3,3)\n",
      "(3,4)\n",
      "(3,5)\n",
      "(3,6)\n",
      "(3,7)\n",
      "(3,8)\n",
      "(3,9)\n",
      "(3,10)\n",
      "(3,11)\n",
      "(3,12)\n",
      "(3,13)\n",
      "(3,14)\n",
      "(4,14)\n",
      "(5,14)\n",
      "(6,14)\n",
      "(7,14)\n",
      "(7,15)\n",
      "(8,15)\n",
      "(9,15)\n",
      "(10,15)\n",
      "(11,15)\n",
      "(12,15)\n",
      "(13,15)\n",
      "(14,15)\n",
      "(15,15)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = GridworldEnv()\n",
    "policy, v = value_iteration(env)\n",
    "print(\"Reshaped Grid Policy (0=up, 1=right, 2=down, 3=left):\")\n",
    "policy_matrix = np.reshape(np.argmax(policy, axis=1), env.shape)\n",
    "print(policy_matrix)\n",
    "#print(\"Reshaped Grid Value Function:\")\n",
    "#print(v.reshape(env.shape))\n",
    "map_matrix = np.load('lab11_map_matrix.npy') #first state\n",
    "#map_matrix[2,2,:]=255 #white start\n",
    "x =2\n",
    "y =2\n",
    "#while not (map_matrix[x,y]==np.array([255,0,0])).all():\n",
    "while True:\n",
    "    next_pos =  policy_matrix[x][y]\n",
    "    if next_pos == 0: x=x-1\n",
    "    elif next_pos == 1 : y=y+1\n",
    "    elif next_pos == 2 : x= x+1\n",
    "    elif next_pos == 3: y=y-1\n",
    "    else: print ('error')\n",
    "    print ('({},{})'.format(x,y))\n",
    "    if (map_matrix[x,y]==np.array([255,0,0])).all():\n",
    "        break\n",
    "    map_matrix[x,y,:]=255 #trail\n",
    "plt.imshow(map_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42]\n",
      "[315, 316, 335, 336]\n",
      "[44, 45, 46, 47, 48, 49, 109, 123, 129, 135, 136, 137, 138, 139, 143, 149, 163, 164, 165, 166, 167, 168, 169, 183, 189, 203, 209, 223, 229, 243, 249, 263, 269, 280, 281, 282, 283, 289, 309, 310, 311, 312]\n"
     ]
    }
   ],
   "source": [
    "map_matrix = np.load('lab11_map_matrix.npy') #first state\n",
    "start_s = [] #start point\n",
    "target_s = [] #target point\n",
    "obstacle_s= [] #obstacle point\n",
    "for x in range(map_matrix.shape[0]):\n",
    "    for y in range(map_matrix.shape[1]):\n",
    "        if (map_matrix[x,y]==np.array([255,0,0])).all(): #red\n",
    "            target_s.append(x*20+y)\n",
    "        elif (map_matrix[x,y]==np.array([255,255,255])).all():#white\n",
    "            start_s.append(x*20+y)\n",
    "        elif (map_matrix[x,y]==np.array([0,30,0])).all():#green\n",
    "            obstacle_s.append(x*20+y)\n",
    "        else:\n",
    "            continue\n",
    "print (start_s)\n",
    "print (target_s)\n",
    "print (obstacle_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reward_matrix = np.load('lab11_reward_matrix.npy')#reward\n",
    "plt.imshow(reward_matrix)\n",
    "plt.show()\n",
    "map_matrix = np.load('lab11_map_matrix.npy') #first state\n",
    "plt.imshow(map_matrix)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
