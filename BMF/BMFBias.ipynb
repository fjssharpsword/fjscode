{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 2313189, User = 10216, Item = 96324, Sparsity = 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 7.0614e+06: 100%|██████████| 10000/10000 [4:38:47<00:00,  1.60s/it] \n",
      "Finished [100%]: Average Loss = 7.0607e+06\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0811 04:27:39.656300 140377736296192 inference.py:248] Finished [100%]: Average Loss = 7.0607e+06\n",
      "100%|██████████| 500/500 [00:05<00:00, 95.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@16:1.3327729249836142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 8.0402e+06: 100%|██████████| 10000/10000 [9:31:11<00:00,  3.36s/it]  \n",
      "Finished [100%]: Average Loss = 8.0388e+06\n",
      "I0811 14:03:40.021590 140377736296192 inference.py:248] Finished [100%]: Average Loss = 8.0388e+06\n",
      "100%|██████████| 500/500 [00:06<00:00, 77.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@32:1.3463370430432309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.4368e+07:  29%|██▊       | 2861/10000 [9:13:00<14:24:07,  7.26s/it] "
     ]
    }
   ],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.08.10\n",
    "@function: BMFBias(Bayesian Matrix Factorization with bias) \n",
    "           Datatset: KnowledgeBase-CC\n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import heapq\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/kbcc_trainset.csv\" \n",
    "        data = pd.read_csv(filePath, sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "        maxu, maxi, maxr = data['csr'].max()+1, data['ke'].max()+1, data['num'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/kbcc_testset.csv\" \n",
    "        data = pd.read_csv(filePath, sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "    \n",
    "    def list_to_dict(self, dataset):\n",
    "        dataDict = {}\n",
    "        for u,i,r in dataset:\n",
    "            dataDict[int(u), int(i)] = float(r)\n",
    "        return dataDict\n",
    "    \n",
    "    def getInstances(self, dataset):\n",
    "        user = []\n",
    "        item = []\n",
    "        rate = []\n",
    "        for u, i, r in dataset:\n",
    "            user.append(int(u))\n",
    "            item.append(int(i))\n",
    "            rate.append(float(r))\n",
    "        return np.array(user), np.array(item), np.array(rate)\n",
    "    \n",
    "class BMF():\n",
    "    def __init__(self, ds):\n",
    "        self.maxr = ds.maxr\n",
    "        self.maxu = ds.maxu\n",
    "        self.maxi = ds.maxi\n",
    "        #get the trainset and testset\n",
    "        train_u, train_i, train_r = ds.getInstances(ds.trainset)\n",
    "        shuffled_idx = np.random.permutation(np.arange(len(train_u)))\n",
    "        self.train_u = train_u[shuffled_idx]\n",
    "        self.train_i = train_i[shuffled_idx]\n",
    "        self.train_r = train_r[shuffled_idx]\n",
    "        assert(len(self.train_u) == len(self.train_i) and len(self.train_i) == len(self.train_r)) \n",
    "        self.test_u, self.test_i, self.test_r = ds.getInstances(ds.testset)\n",
    "        assert(len(self.test_u) == len(self.test_i) and len(self.test_i) == len(self.test_r))\n",
    "    \n",
    "    def train_BMF(self, K=8):\n",
    "        self.x_u = theano.shared(self.train_u)\n",
    "        self.x_i = theano.shared(self.train_i)\n",
    "        self.y_r = theano.shared(self.train_r)\n",
    "        with pm.Model() as self.bmf:#bulid probabilistic model\n",
    "            meanr = self.maxr/2\n",
    "            # Creating the model\n",
    "            P = pm.Normal('P', mu=0, sd=meanr, shape=(self.maxu, K))\n",
    "            Q = pm.Normal('Q', mu=0, sd=meanr, shape=(self.maxi, K))\n",
    "            #bias\n",
    "            b_u = pm.Normal('b_u', mu=0, sd=meanr, shape=self.maxu)\n",
    "            b_i = pm.Normal('b_i', mu=0, sd=meanr, shape=self.maxi)\n",
    "            u = pm.Normal('u', mu=0, sd=meanr)\n",
    "            tY = pm.Deterministic('tY', tt.add(tt.add(tt.add(b_u[self.x_u],b_i[self.x_i]),tt.sum(P[self.x_u,:]*Q[self.x_i,:], axis=1)),u))\n",
    "            #likelihood function\n",
    "            Y = pm.Normal('Y', mu=tY, sd=meanr, observed=self.y_r)\n",
    "            \n",
    "        with self.bmf: #train the probabilistic model by Bayesian inference\n",
    "            tstart = time.time()\n",
    "            logging.info('Start training BMF')\n",
    "            approx = pm.fit(n=10000, method=pm.ADVI())\n",
    "            trace = approx.sample(draws=500)\n",
    "            elapsed = time.time() - tstart \n",
    "            logging.info('Complete BMF training in %d seconds' % int(elapsed))\n",
    "        return trace\n",
    "            \n",
    "    def eval_BMF(self, trace):\n",
    "        self.x_u.set_value(self.test_u)\n",
    "        self.x_i.set_value(self.test_i)\n",
    "        self.y_r.set_value(self.test_r)\n",
    "        with self.bmf:\n",
    "            ppc = pm.sample_posterior_predictive(trace, progressbar=True)\n",
    "            pY = ppc['Y'].mean(axis=0)\n",
    "        assert(pY.shape[0]==self.test_r.shape[0])\n",
    "        squaredError = []\n",
    "        for i in range(pY.shape[0]):\n",
    "            error=self.test_r[i] - pY[i]\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        return rmse\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\n",
    "    bmf = BMF(ds)#negative sample ratio\n",
    "    for K in [16, 32, 64]:#8, \n",
    "        trace = bmf.train_BMF(K)\n",
    "        rmse = bmf.eval_BMF(trace)\n",
    "        print(\"RMSE@{}:{}\".format(K, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.5768e+06: 100%|██████████| 20000/20000 [12:39:36<00:00,  2.08s/it]  \n",
      "Finished [100%]: Average Loss = 2.5767e+06\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0803 13:33:45.902980 140106723780352 inference.py:248] Finished [100%]: Average Loss = 2.5767e+06\n",
      "100%|██████████| 2000/2000 [00:33<00:00, 59.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE@64:0.9552209868260392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.08.01\n",
    "@function: BMFBias(Bayesian Matrix Factorization with bias) \n",
    "           Datatset: MovieLens-1m:https://grouplens.org/datasets/movielens/  \n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import heapq\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.train.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        maxu, maxi, maxr = data['user'].max()+1, data['item'].max()+1, data['rating'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.test.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "    \n",
    "    def list_to_dict(self, dataset):\n",
    "        dataDict = {}\n",
    "        for u,i,r in dataset:\n",
    "            dataDict[int(u), int(i)] = float(r)\n",
    "        return dataDict\n",
    "    \n",
    "    def getInstances(self, dataset):\n",
    "        user = []\n",
    "        item = []\n",
    "        rate = []\n",
    "        for u, i, r in dataset:\n",
    "            user.append(int(u))\n",
    "            item.append(int(i))\n",
    "            rate.append(float(r))\n",
    "        return np.array(user), np.array(item), np.array(rate)\n",
    "    \n",
    "class BMF():\n",
    "    def __init__(self, ds):\n",
    "        self.maxr = ds.maxr\n",
    "        self.maxu = ds.maxu\n",
    "        self.maxi = ds.maxi\n",
    "        #get the trainset and testset\n",
    "        train_u, train_i, train_r = ds.getInstances(ds.trainset)\n",
    "        shuffled_idx = np.random.permutation(np.arange(len(train_u)))\n",
    "        self.train_u = train_u[shuffled_idx]\n",
    "        self.train_i = train_i[shuffled_idx]\n",
    "        self.train_r = train_r[shuffled_idx]\n",
    "        assert(len(self.train_u) == len(self.train_i) and len(self.train_i) == len(self.train_r)) \n",
    "        self.test_u, self.test_i, self.test_r = ds.getInstances(ds.testset)\n",
    "        assert(len(self.test_u) == len(self.test_i) and len(self.test_i) == len(self.test_r))\n",
    "    \n",
    "    def train_BMF(self, K=8):\n",
    "        self.x_u = theano.shared(self.train_u)\n",
    "        self.x_i = theano.shared(self.train_i)\n",
    "        self.y_r = theano.shared(self.train_r)\n",
    "        with pm.Model() as self.bmf:#bulid probabilistic model\n",
    "            meanr = self.maxr/2\n",
    "            # Creating the model\n",
    "            P = pm.Normal('P', mu=0, sd=meanr, shape=(self.maxu, K))\n",
    "            Q = pm.Normal('Q', mu=0, sd=meanr, shape=(self.maxi, K))\n",
    "            #bias\n",
    "            b_u = pm.Normal('b_u', mu=0, sd=meanr, shape=self.maxu)\n",
    "            b_i = pm.Normal('b_i', mu=0, sd=meanr, shape=self.maxi)\n",
    "            u = pm.Normal('u', mu=0, sd=meanr)\n",
    "            tY = pm.Deterministic('tY', tt.add(tt.add(tt.add(b_u[self.x_u],b_i[self.x_i]),tt.sum(P[self.x_u,:]*Q[self.x_i,:], axis=1)),u))\n",
    "            #likelihood function\n",
    "            Y = pm.Normal('Y', mu=tY, sd=meanr, observed=self.y_r)\n",
    "            \n",
    "        with self.bmf: #train the probabilistic model by Bayesian inference\n",
    "            tstart = time.time()\n",
    "            logging.info('Start training BMF')\n",
    "            approx = pm.fit(n=20000, method=pm.ADVI())\n",
    "            trace = approx.sample(draws=2000)\n",
    "            elapsed = time.time() - tstart \n",
    "            logging.info('Complete BMF training in %d seconds' % int(elapsed))\n",
    "        return trace\n",
    "            \n",
    "    def eval_BMF(self, trace):\n",
    "        self.x_u.set_value(self.test_u)\n",
    "        self.x_i.set_value(self.test_i)\n",
    "        self.y_r.set_value(self.test_r)\n",
    "        with self.bmf:\n",
    "            ppc = pm.sample_posterior_predictive(trace, progressbar=True)\n",
    "            pY = ppc['Y'].mean(axis=0)\n",
    "        assert(pY.shape[0]==self.test_r.shape[0])\n",
    "        squaredError = []\n",
    "        for i in range(pY.shape[0]):\n",
    "            error=self.test_r[i] - pY[i]\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        return rmse\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\n",
    "    bmf = BMF(ds)#negative sample ratio\n",
    "    for K in [8, 16, 32]:#64\n",
    "        trace = bmf.train_BMF(K)\n",
    "        rmse = bmf.eval_BMF(trace)\n",
    "        print(\"RMSE@{}:{}\".format(K, rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
