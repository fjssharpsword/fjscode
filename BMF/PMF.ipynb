{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 0.0444\n",
      "Training RMSE: 1.807433, Val RMSE 2.637636\n",
      "Training RMSE: 1.807421, Val RMSE 2.637620\n",
      "Training RMSE: 1.807410, Val RMSE 2.637608\n",
      "Training RMSE: 1.807399, Val RMSE 2.637594\n",
      "Training RMSE: 1.807388, Val RMSE 2.637577\n",
      "Training RMSE: 1.807378, Val RMSE 2.637561\n",
      "Training RMSE: 1.807366, Val RMSE 2.637547\n",
      "Training RMSE: 1.807355, Val RMSE 2.637532\n",
      "Training RMSE: 1.807342, Val RMSE 2.637519\n",
      "Training RMSE: 1.807331, Val RMSE 2.637506\n",
      "Training RMSE: 1.807320, Val RMSE 2.637488\n",
      "Training RMSE: 1.807311, Val RMSE 2.637475\n",
      "Training RMSE: 1.807301, Val RMSE 2.637462\n",
      "Training RMSE: 1.807291, Val RMSE 2.637452\n",
      "Training RMSE: 1.807281, Val RMSE 2.637444\n",
      "Training RMSE: 1.807271, Val RMSE 2.637428\n",
      "Training RMSE: 1.807261, Val RMSE 2.637411\n",
      "Training RMSE: 1.807250, Val RMSE 2.637397\n",
      "Training RMSE: 1.807240, Val RMSE 2.637387\n",
      "Training RMSE: 1.807229, Val RMSE 2.637376\n",
      "RMSE@8:2.6855170658436287\n",
      "Training RMSE: 1.807641, Val RMSE 2.636408\n",
      "Training RMSE: 1.807619, Val RMSE 2.636377\n",
      "Training RMSE: 1.807595, Val RMSE 2.636352\n",
      "Training RMSE: 1.807573, Val RMSE 2.636332\n",
      "Training RMSE: 1.807551, Val RMSE 2.636305\n",
      "Training RMSE: 1.807530, Val RMSE 2.636280\n",
      "Training RMSE: 1.807507, Val RMSE 2.636260\n",
      "Training RMSE: 1.807484, Val RMSE 2.636232\n",
      "Training RMSE: 1.807464, Val RMSE 2.636208\n",
      "Training RMSE: 1.807444, Val RMSE 2.636180\n",
      "Training RMSE: 1.807423, Val RMSE 2.636150\n",
      "Training RMSE: 1.807402, Val RMSE 2.636118\n",
      "Training RMSE: 1.807383, Val RMSE 2.636089\n",
      "Training RMSE: 1.807363, Val RMSE 2.636060\n",
      "Training RMSE: 1.807342, Val RMSE 2.636029\n",
      "Training RMSE: 1.807320, Val RMSE 2.635997\n",
      "Training RMSE: 1.807296, Val RMSE 2.635966\n",
      "Training RMSE: 1.807273, Val RMSE 2.635940\n",
      "Training RMSE: 1.807252, Val RMSE 2.635908\n",
      "Training RMSE: 1.807231, Val RMSE 2.635877\n",
      "RMSE@16:2.685292182795217\n",
      "Training RMSE: 1.808077, Val RMSE 2.634520\n",
      "Training RMSE: 1.808036, Val RMSE 2.634470\n",
      "Training RMSE: 1.807992, Val RMSE 2.634418\n",
      "Training RMSE: 1.807947, Val RMSE 2.634371\n",
      "Training RMSE: 1.807904, Val RMSE 2.634312\n",
      "Training RMSE: 1.807864, Val RMSE 2.634262\n",
      "Training RMSE: 1.807823, Val RMSE 2.634199\n",
      "Training RMSE: 1.807779, Val RMSE 2.634149\n",
      "Training RMSE: 1.807738, Val RMSE 2.634104\n",
      "Training RMSE: 1.807696, Val RMSE 2.634051\n",
      "Training RMSE: 1.807652, Val RMSE 2.633992\n",
      "Training RMSE: 1.807610, Val RMSE 2.633937\n",
      "Training RMSE: 1.807568, Val RMSE 2.633877\n",
      "Training RMSE: 1.807523, Val RMSE 2.633818\n",
      "Training RMSE: 1.807479, Val RMSE 2.633757\n",
      "Training RMSE: 1.807436, Val RMSE 2.633704\n",
      "Training RMSE: 1.807394, Val RMSE 2.633657\n",
      "Training RMSE: 1.807349, Val RMSE 2.633601\n",
      "Training RMSE: 1.807302, Val RMSE 2.633524\n",
      "Training RMSE: 1.807256, Val RMSE 2.633456\n",
      "RMSE@32:2.685274854475652\n",
      "Training RMSE: 1.808927, Val RMSE 2.636778\n",
      "Training RMSE: 1.808838, Val RMSE 2.636671\n",
      "Training RMSE: 1.808746, Val RMSE 2.636566\n",
      "Training RMSE: 1.808652, Val RMSE 2.636461\n",
      "Training RMSE: 1.808560, Val RMSE 2.636341\n",
      "Training RMSE: 1.808467, Val RMSE 2.636230\n",
      "Training RMSE: 1.808376, Val RMSE 2.636128\n",
      "Training RMSE: 1.808290, Val RMSE 2.636033\n",
      "Training RMSE: 1.808200, Val RMSE 2.635924\n",
      "Training RMSE: 1.808114, Val RMSE 2.635825\n",
      "Training RMSE: 1.808029, Val RMSE 2.635723\n",
      "Training RMSE: 1.807941, Val RMSE 2.635606\n",
      "Training RMSE: 1.807853, Val RMSE 2.635491\n",
      "Training RMSE: 1.807765, Val RMSE 2.635373\n",
      "Training RMSE: 1.807676, Val RMSE 2.635245\n",
      "Training RMSE: 1.807584, Val RMSE 2.635120\n",
      "Training RMSE: 1.807493, Val RMSE 2.634980\n",
      "Training RMSE: 1.807403, Val RMSE 2.634857\n",
      "Training RMSE: 1.807313, Val RMSE 2.634737\n",
      "Training RMSE: 1.807221, Val RMSE 2.634622\n",
      "RMSE@64:2.686393332074473\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.07.31\n",
    "@function: baseline PMF(Probabilistic Matrix Factorization)\n",
    "           Datatset: MovieLens-1m:https://grouplens.org/datasets/movielens/  \n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import heapq\n",
    "import math\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.train.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        maxu, maxi, maxr = data['user'].max()+1, data['item'].max()+1, data['rating'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.test.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "    \n",
    "    def list_to_dict(self, dataset):\n",
    "        dataDict = {}\n",
    "        for u,i,r in dataset:\n",
    "            dataDict[int(u), int(i)] = float(r)\n",
    "        return dataDict\n",
    "    \n",
    "    def generate_neg_sample(self, dataset, maxi, num_ng):\n",
    "        datadict = self.list_to_dict(dataset)\n",
    "        trainPN = []\n",
    "        for i in dataset:\n",
    "            trainPN.append([i[0],i[1],i[2]])\n",
    "            for t in range(num_ng):\n",
    "                j = np.random.randint(maxi)\n",
    "                while (i[0], j) in datadict:\n",
    "                    j = np.random.randint(maxi)\n",
    "                trainPN.append([i[0], j, 0.0])\n",
    "        return trainPN\n",
    "    \n",
    "class PMF:\n",
    "    def __init__(self, num_feat=8, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
    "        self.num_feat = num_feat\n",
    "        self.epsilon = epsilon\n",
    "        self._lambda = _lambda\n",
    "        self.momentum = momentum\n",
    "        self.maxepoch = maxepoch\n",
    "        self.num_batches = num_batches\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.w_C = None\n",
    "        self.w_I = None\n",
    "\n",
    "        self.err_train = []\n",
    "        self.err_val = []\n",
    "        \n",
    "    def fit(self, train_vec, val_vec):   \n",
    "        # mean subtraction\n",
    "        self.mean_inv = np.mean(train_vec[:,2])\n",
    "        \n",
    "        pairs_tr = train_vec.shape[0]\n",
    "        pairs_va = val_vec.shape[0]\n",
    "        \n",
    "        # 1-p-i, 2-m-c\n",
    "        num_inv = int(max(np.amax(train_vec[:,0]), np.amax(val_vec[:,0]))) + 1\n",
    "        num_com = int(max(np.amax(train_vec[:,1]), np.amax(val_vec[:,1]))) + 1\n",
    "\n",
    "        incremental = False\n",
    "        if ((not incremental) or (self.w_C is None)):\n",
    "            # initialize\n",
    "            self.epoch = 0\n",
    "            self.w_C = 0.1 * np.random.randn(num_com, self.num_feat)\n",
    "            self.w_I = 0.1 * np.random.randn(num_inv, self.num_feat)\n",
    "            \n",
    "            self.w_C_inc = np.zeros((num_com, self.num_feat))\n",
    "            self.w_I_inc = np.zeros((num_inv, self.num_feat))\n",
    "        \n",
    "        \n",
    "        while self.epoch < self.maxepoch:\n",
    "            self.epoch += 1\n",
    "\n",
    "            # Shuffle training truples\n",
    "            shuffled_order = np.arange(train_vec.shape[0])\n",
    "            np.random.shuffle(shuffled_order)\n",
    "\n",
    "            # Batch update\n",
    "            for batch in range(self.num_batches):\n",
    "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
    "\n",
    "                batch_idx = np.mod(np.arange(self.batch_size * batch,\n",
    "                                             self.batch_size * (batch+1)),\n",
    "                                   shuffled_order.shape[0])\n",
    "\n",
    "                batch_invID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
    "                batch_comID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
    "\n",
    "                # Compute Objective Function\n",
    "                pred_out = np.sum(np.multiply(self.w_I[batch_invID,:], \n",
    "                                                self.w_C[batch_comID,:]),\n",
    "                                axis=1) # mean_inv subtracted\n",
    "\n",
    "                rawErr = pred_out - train_vec[shuffled_order[batch_idx], 2] + self.mean_inv\n",
    "\n",
    "                # Compute gradients\n",
    "                Ix_C = 2 * np.multiply(rawErr[:, np.newaxis], self.w_I[batch_invID,:]) \\\n",
    "                        + self._lambda * self.w_C[batch_comID,:]\n",
    "                Ix_I = 2 * np.multiply(rawErr[:, np.newaxis], self.w_C[batch_comID,:]) \\\n",
    "                        + self._lambda * self.w_I[batch_invID,:]\n",
    "            \n",
    "                dw_C = np.zeros((num_com, self.num_feat))\n",
    "                dw_I = np.zeros((num_inv, self.num_feat))\n",
    "\n",
    "                # loop to aggreate the gradients of the same element\n",
    "                for i in range(self.batch_size):\n",
    "                    dw_C[batch_comID[i],:] += Ix_C[i,:]\n",
    "                    dw_I[batch_invID[i],:] += Ix_I[i,:]\n",
    "\n",
    "\n",
    "                # Update with momentum\n",
    "                self.w_C_inc = self.momentum * self.w_C_inc + self.epsilon * dw_C / self.batch_size\n",
    "                self.w_I_inc = self.momentum * self.w_I_inc + self.epsilon * dw_I / self.batch_size\n",
    "\n",
    "\n",
    "                self.w_C = self.w_C - self.w_C_inc\n",
    "                self.w_I = self.w_I - self.w_I_inc\n",
    "\n",
    "                # Compute Objective Function after\n",
    "                if batch == self.num_batches - 1:\n",
    "                    pred_out = np.sum(np.multiply(self.w_I[np.array(train_vec[:,0], dtype='int32'),:],\n",
    "                                                    self.w_C[np.array(train_vec[:,1], dtype='int32'),:]),\n",
    "                                        axis=1) # mean_inv subtracted\n",
    "                    rawErr = pred_out - train_vec[:, 2] + self.mean_inv\n",
    "                    obj = LA.norm(rawErr) ** 2 \\\n",
    "                            + 0.5*self._lambda*(LA.norm(self.w_I) ** 2 + LA.norm(self.w_C) ** 2)\n",
    "\n",
    "                    self.err_train.append(np.sqrt(obj/pairs_tr))\n",
    "\n",
    "                # Compute validation error\n",
    "                if batch == self.num_batches - 1:\n",
    "                    pred_out = np.sum(np.multiply(self.w_I[np.array(val_vec[:,0], dtype='int32'),:],\n",
    "                                                    self.w_C[np.array(val_vec[:,1], dtype='int32'),:]),\n",
    "                                        axis=1) # mean_inv subtracted\n",
    "                    rawErr = pred_out - val_vec[:, 2] + self.mean_inv\n",
    "                    self.err_val.append(LA.norm(rawErr)/np.sqrt(pairs_va))\n",
    "\n",
    "                # Print info\n",
    "                if batch == self.num_batches - 1:\n",
    "                    print ('Training RMSE: %f, Val RMSE %f' % (self.err_train[-1], self.err_val[-1]))\n",
    "    \n",
    "    def predict(self, invID, comID): \n",
    "        return np.dot(self.w_C[comID,:], self.w_I[invID,:]) + self.mean_inv\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\n",
    "    trainPN = ds.generate_neg_sample(ds.trainset, ds.maxi, num_ng=2)\n",
    "    for K in [8, 16, 32, 64]:\n",
    "        pmf = PMF(num_feat=K)\n",
    "        valtest = random.sample(ds.trainset,int(0.2*len(ds.trainset)))\n",
    "        pmf.fit(np.array(trainPN), np.array(valtest))\n",
    "        squaredError = []\n",
    "        for u,i,r in ds.testset:\n",
    "            error=r - pmf.predict(int(u),int(i))\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        print(\"RMSE@{}:{}\".format(K, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
