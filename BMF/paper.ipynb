{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8  \n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.08.10\n",
    "@function: BMF(Bayesian Matrix Factorization) \n",
    "           Datatset: MovieLens-1m:https://grouplens.org/datasets/movielens/  \n",
    "           Evaluation: RMSE\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import heapq\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        self.trainset, self.testset, self.maxu, self.maxi, self.maxr = self._getDataset_as_list()\n",
    "        \n",
    "    def _getDataset_as_list(self):\n",
    "        #trainset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.train.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        maxu, maxi, maxr = data['user'].max()+1, data['item'].max()+1, data['rating'].max()\n",
    "        print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "        trainset = data.values.tolist()\n",
    "        #testset\n",
    "        filePath = \"/data/fjsdata/BMF/ml-1m.test.rating\" \n",
    "        data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "        testset = data.values.tolist()\n",
    "        return trainset, testset, maxu, maxi, maxr \n",
    "    \n",
    "    def list_to_matrix(self, dataset, maxu, maxi):              \n",
    "        dataMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "        for u,i,r in dataset:\n",
    "            dataMat[int(u)][int(i)] = float(r)\n",
    "        return np.array(dataMat)\n",
    "    \n",
    "    def list_to_dict(self, dataset):\n",
    "        dataDict = {}\n",
    "        for u,i,r in dataset:\n",
    "            dataDict[int(u), int(i)] = float(r)\n",
    "        return dataDict\n",
    "    \n",
    "    def getInstances(self, dataset):\n",
    "        user = []\n",
    "        item = []\n",
    "        rate = []\n",
    "        for u, i, r in dataset:\n",
    "            user.append(int(u))\n",
    "            item.append(int(i))\n",
    "            rate.append(float(r))\n",
    "        return np.array(user), np.array(item), np.array(rate)\n",
    "    \n",
    "class BMF():\n",
    "    def __init__(self, ds):\n",
    "        self.maxr = ds.maxr\n",
    "        self.maxu = ds.maxu\n",
    "        self.maxi = ds.maxi\n",
    "        #get the trainset and testset\n",
    "        train_u, train_i, train_r = ds.getInstances(ds.trainset)\n",
    "        shuffled_idx = np.random.permutation(np.arange(len(train_u)))\n",
    "        self.train_u = train_u[shuffled_idx]\n",
    "        self.train_i = train_i[shuffled_idx]\n",
    "        self.train_r = train_r[shuffled_idx]\n",
    "        assert(len(self.train_u) == len(self.train_i) and len(self.train_i) == len(self.train_r)) \n",
    "        self.test_u, self.test_i, self.test_r = ds.getInstances(ds.testset)\n",
    "        assert(len(self.test_u) == len(self.test_i) and len(self.test_i) == len(self.test_r))\n",
    "    \n",
    "    def train_BMF(self, K=8):\n",
    "        meanr = self.maxr/2\n",
    "        self.x_u = theano.shared(self.train_u)\n",
    "        self.x_i = theano.shared(self.train_i)\n",
    "        self.y_r = theano.shared(self.train_r)\n",
    "        with pm.Model() as self.bmf:#bulid probabilistic model\n",
    "            # Creating the model\n",
    "            P = pm.Normal('P', mu=0, sd=meanr, shape=(self.maxu, K))\n",
    "            Q = pm.Normal('Q', mu=0, sd=meanr, shape=(self.maxi, K))\n",
    "            tY = pm.Deterministic('tY', pm.math.sum(P[self.x_u,:]*Q[self.x_i,:], axis=1))\n",
    "            Y = pm.Normal('Y', mu=tY, sd=meanr, observed=self.y_r)#pm.Categorical\n",
    "            \n",
    "        with self.bmf: #train the probabilistic model by Bayesian inference\n",
    "            tstart = time.time()\n",
    "            logging.info('Start training BMF')\n",
    "            mapst=pm.find_MAP() #get the map point\n",
    "            approx = pm.fit(n=10000, method=pm.ADVI())\n",
    "            trace = approx.sample(draws=500)\n",
    "            elapsed = time.time() - tstart \n",
    "            logging.info('Complete BMF training in %d seconds' % int(elapsed))\n",
    "        return trace, mapst\n",
    "            \n",
    "    def eval_BMF(self, trace):\n",
    "        self.x_u.set_value(self.test_u)\n",
    "        self.x_i.set_value(self.test_i)\n",
    "        self.y_r.set_value(self.test_r)\n",
    "        with self.bmf:\n",
    "            ppc = pm.sample_posterior_predictive(trace, progressbar=True)\n",
    "            pY = ppc['Y'].mean(axis=0)\n",
    "            #pY = np.max(ppc['Y'],axis=0)\n",
    "        assert(pY.shape[0]==self.test_r.shape[0])\n",
    "        squaredError = []\n",
    "        for i in range(pY.shape[0]):\n",
    "            error=self.test_r[i] - pY[i]\n",
    "            squaredError.append(error * error)\n",
    "        rmse =math.sqrt(sum(squaredError) / len(squaredError))\n",
    "        return rmse\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    ds = DataSet()#loading dataset\n",
    "    bmf = BMF(ds)\n",
    "    K=8\n",
    "    trace,mapst = bmf.train_BMF(K)\n",
    "    rmse = bmf.eval_BMF(trace)\n",
    "    print(\"RMSE@{}:{}\".format(K, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 0.0444\n",
      "                  user           item    rating\n",
      "Mean      3.023537e+03     872.860828  3.581378\n",
      "Std. dev  1.728320e+03     738.213243  1.116791\n",
      "Variance  2.987090e+06  544958.792605  1.247222\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filePath = \"/data/fjsdata/BMF/ml-1m.train.rating\" \n",
    "data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "maxu, maxi, maxr = data['user'].max()+1, data['item'].max()+1, data['rating'].max()\n",
    "print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "rs = pd.DataFrame([data.mean(), data.std(), data.var()], index=['Mean', 'Std. dev', 'Variance'])\n",
    "print (rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 2313189, User = 10216, Item = 96324, Sparsity = 0.0024\n",
      "                   csr            ke       num\n",
      "Mean      4.788496e+03  5.249678e+04  2.208648\n",
      "Std. dev  2.657450e+03  2.589617e+04  1.961752\n",
      "Variance  7.062041e+06  6.706117e+08  3.848470\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filePath = \"/data/fjsdata/BMF/kbcc_trainset.csv\" \n",
    "data = pd.read_csv(filePath, sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "maxu, maxi, maxr = data['csr'].max()+1, data['ke'].max()+1, data['num'].max()\n",
    "print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "rs = pd.DataFrame([data.mean(), data.std(), data.var()], index=['Mean', 'Std. dev', 'Variance'])\n",
    "print (rs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
