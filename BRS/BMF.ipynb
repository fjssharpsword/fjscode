{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 55186\n",
      "\tItem Num: 9915\n",
      "\tData Size: 1445622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-07-24 02:10:26,486]: building the BMF model\n",
      "[2019-07-24 02:41:46,664]: done building BMF model\n",
      "[2019-07-24 02:41:46,726]: Start BMF sampling\n",
      "Average Loss = 8.0852e+09:  29%|██▊       | 286/1000 [6:50:06<14:23:39, 72.58s/it] \n",
      "Interrupted at 286 [28%]: Average Loss = 8.0742e+09\n",
      "[2019-07-24 09:42:26,364]: Interrupted at 286 [28%]: Average Loss = 8.0742e+09\n"
     ]
    }
   ],
   "source": [
    "# -*- Encoding:UTF-8 -*-\n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.07.22\n",
    "@function: Implementing BMF(Bayesian Matrix Factorization) By VI\n",
    "           Dataset: Pinterest-20\n",
    "           Evaluating: hitradio,ndcg\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as t\n",
    "import heapq\n",
    "import math\n",
    "\n",
    "def getTraindata():\n",
    "    data = []\n",
    "    filePath = '/data/fjsdata/ctKngBase/ml/pinterest-20.train.rating'\n",
    "    u = 0\n",
    "    i = 0\n",
    "    maxr = 0.0\n",
    "    with open(filePath, 'r') as f:\n",
    "        for line in f:\n",
    "            if line:\n",
    "                lines = line[:-1].split(\"\\t\")\n",
    "                user = int(lines[0])\n",
    "                item = int(lines[1])\n",
    "                score = float(lines[2])\n",
    "                data.append((user, item, score))\n",
    "                if user > u: u = user\n",
    "                if item > i: i = item\n",
    "                if score > maxr: maxr = score\n",
    "    print(\"Loading Success!\\n\"\n",
    "                  \"Data Info:\\n\"\n",
    "                  \"\\tUser Num: {}\\n\"\n",
    "                  \"\\tItem Num: {}\\n\"\n",
    "                  \"\\tData Size: {}\".format(u, i, len(data)))\n",
    "    \n",
    "    R = np.zeros([u+1, i+1], dtype=np.float32)\n",
    "    for i in data:\n",
    "        user = i[0]\n",
    "        item = i[1]\n",
    "        rating = i[2]\n",
    "        R[user][item] = rating\n",
    "    return R\n",
    "\n",
    "def getTestdata():\n",
    "    testset = []\n",
    "    filePath = '/data/fjsdata/ctKngBase/ml/pinterest-20.test.negative'\n",
    "    with open(filePath, 'r') as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != '':\n",
    "            arr = line.split('\\t')\n",
    "            u = eval(arr[0])[0]\n",
    "            testset.append([u, eval(arr[0])[1]])#one postive item\n",
    "            for i in arr[1:]:\n",
    "                testset.append([u, int(i)]) #99 negative items\n",
    "            line = fd.readline()\n",
    "    return testset\n",
    "\n",
    "def getHitRatio(ranklist, targetItem):\n",
    "    for item in ranklist:\n",
    "        if item == targetItem:\n",
    "            return 1\n",
    "    return 0\n",
    "def getNDCG(ranklist, targetItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == targetItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0\n",
    "\n",
    "def build_BMF(R, K, alpha=2, std=0.01):\n",
    "    \n",
    "    alpha_u = 1 / R.var(axis=1).mean()\n",
    "    alpha_v = 1 / R.var(axis=0).mean()\n",
    "\n",
    "    logging.info('building the BMF model')\n",
    "    n, m = R.shape\n",
    "    with pm.Model() as bmf:\n",
    "        U = pm.MvNormal('U', mu=0, tau=alpha_u * np.eye(K), shape=(n, K), testval=np.random.randn(n, K) * std)\n",
    "        V = pm.MvNormal('V', mu=0, tau=alpha_v * np.eye(K), shape=(m, K), testval=np.random.randn(m, K) * std)\n",
    "        nR = pm.Normal('nR', mu=t.dot(U, V.T), tau=alpha * np.ones(R.shape),observed=R)\n",
    "    logging.info('done building BMF model')\n",
    "    return bmf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO,format='[%(asctime)s]: %(message)s')\n",
    "    \n",
    "    # Read data and build BMF model.\n",
    "    R = getTraindata()\n",
    "    bmf = build_BMF(R, K=64)#dim is the number of latent factors\n",
    "\n",
    "    with bmf:# sample with BMF\n",
    "        tstart = time.time()\n",
    "        logging.info('Start BMF sampling')\n",
    "        inference = pm.ADVI()\n",
    "        approx = pm.fit(n=1000, method=inference)\n",
    "        trace = approx.sample(draws=500)\n",
    "        elapsed = time.time() - tstart    \n",
    "        logging.info('Complete BMF sampling in %d seconds' % int(elapsed))\n",
    "        \n",
    "    with bmf:#evaluation\n",
    "        testset = getTestdata()\n",
    "        ppc = pm.sample_posterior_predictive(trace, progressbar=True)\n",
    "        nR = np.mean(ppc['nR'],0)#three dims, calcuate the mean with the first dim for posterior\n",
    "        hits = []\n",
    "        ndcgs = []\n",
    "        prev_u = testset[0][0]\n",
    "        pos_i = testset[0][1]\n",
    "        scorelist = []\n",
    "        for u, i in testset:\n",
    "            if prev_u == u:\n",
    "                scorelist.append([i,nR[u,i]])\n",
    "            else:\n",
    "                map_item_score = {}\n",
    "                for item, rate in scorelist: #turn dict\n",
    "                    map_item_score[item] = rate\n",
    "                ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)#default Topn=10\n",
    "                hr = getHitRatio(ranklist, pos_i)\n",
    "                hits.append(hr)\n",
    "                ndcg = getNDCG(ranklist, pos_i)\n",
    "                ndcgs.append(ndcg)\n",
    "                #next user\n",
    "                scorelist = []\n",
    "                prev_u = u\n",
    "                pos_i = i\n",
    "                scorelist.append([i,nR[u,i]])\n",
    "        hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "        print(\"HR@10: {}, NDCG@10: {}, At K {}\".format(hitratio, ndcg, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 6039\n",
      "\tItem Num: 3705\n",
      "\tData Size: 994169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-07-23 23:27:45,431]: building the BMF model\n",
      "[2019-07-23 23:28:43,841]: done building BMF model\n",
      "[2019-07-23 23:28:43,846]: Start BMF sampling\n",
      "Average Loss = 2.7484e+08: 100%|██████████| 1000/1000 [53:55<00:00,  3.06s/it]\n",
      "Finished [100%]: Average Loss = 2.7423e+08\n",
      "[2019-07-24 00:23:00,032]: Finished [100%]: Average Loss = 2.7423e+08\n",
      "[2019-07-24 00:24:37,526]: Complete BMF sampling in 3353 seconds\n",
      "100%|██████████| 500/500 [1:13:32<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@10: 0.10200364298724955, NDCG@10: 0.04524941138321496, At K 64\n"
     ]
    }
   ],
   "source": [
    "# -*- Encoding:UTF-8 -*-\n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.07.22\n",
    "@function: Implementing BMF(Bayesian Matrix Factorization) By VI\n",
    "           Dataset: Movielen Dataset(ml-1m) \n",
    "           Evaluating: hitradio,ndcg\n",
    "'''\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as t\n",
    "import heapq\n",
    "import math\n",
    "\n",
    "def getTraindata():\n",
    "    data = []\n",
    "    filePath = '/data/fjsdata/ctKngBase/ml/ml-1m.train.rating'\n",
    "    u = 0\n",
    "    i = 0\n",
    "    maxr = 0.0\n",
    "    with open(filePath, 'r') as f:\n",
    "        for line in f:\n",
    "            if line:\n",
    "                lines = line[:-1].split(\"\\t\")\n",
    "                user = int(lines[0])\n",
    "                item = int(lines[1])\n",
    "                score = float(lines[2])\n",
    "                data.append((user, item, score))\n",
    "                if user > u: u = user\n",
    "                if item > i: i = item\n",
    "                if score > maxr: maxr = score\n",
    "    print(\"Loading Success!\\n\"\n",
    "                  \"Data Info:\\n\"\n",
    "                  \"\\tUser Num: {}\\n\"\n",
    "                  \"\\tItem Num: {}\\n\"\n",
    "                  \"\\tData Size: {}\".format(u, i, len(data)))\n",
    "    \n",
    "    R = np.zeros([u+1, i+1], dtype=np.float32)\n",
    "    for i in data:\n",
    "        user = i[0]\n",
    "        item = i[1]\n",
    "        rating = i[2]\n",
    "        R[user][item] = rating\n",
    "    return R\n",
    "\n",
    "def getTestdata():\n",
    "    testset = []\n",
    "    filePath = '/data/fjsdata/ctKngBase/ml/ml-1m.test.negative'\n",
    "    with open(filePath, 'r') as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != '':\n",
    "            arr = line.split('\\t')\n",
    "            u = eval(arr[0])[0]\n",
    "            testset.append([u, eval(arr[0])[1]])#one postive item\n",
    "            for i in arr[1:]:\n",
    "                testset.append([u, int(i)]) #99 negative items\n",
    "            line = fd.readline()\n",
    "    return testset\n",
    "\n",
    "def getHitRatio(ranklist, targetItem):\n",
    "    for item in ranklist:\n",
    "        if item == targetItem:\n",
    "            return 1\n",
    "    return 0\n",
    "def getNDCG(ranklist, targetItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == targetItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0\n",
    "\n",
    "def build_BMF(R, K, alpha=2, std=0.01):\n",
    "    \n",
    "    alpha_u = 1 / R.var(axis=1).mean()\n",
    "    alpha_v = 1 / R.var(axis=0).mean()\n",
    "\n",
    "    logging.info('building the BMF model')\n",
    "    n, m = R.shape\n",
    "    with pm.Model() as bmf:\n",
    "        U = pm.MvNormal('U', mu=0, tau=alpha_u * np.eye(K), shape=(n, K), testval=np.random.randn(n, K) * std)\n",
    "        V = pm.MvNormal('V', mu=0, tau=alpha_v * np.eye(K), shape=(m, K), testval=np.random.randn(m, K) * std)\n",
    "        nR = pm.Normal('nR', mu=t.dot(U, V.T), tau=alpha * np.ones(R.shape),observed=R)\n",
    "    logging.info('done building BMF model')\n",
    "    return bmf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO,format='[%(asctime)s]: %(message)s')\n",
    "    \n",
    "    # Read data and build BMF model.\n",
    "    R = getTraindata()\n",
    "    bmf = build_BMF(R, K=64)#dim is the number of latent factors\n",
    "\n",
    "    with bmf:# sample with BMF\n",
    "        tstart = time.time()\n",
    "        logging.info('Start BMF sampling')\n",
    "        inference = pm.ADVI()\n",
    "        approx = pm.fit(n=1000, method=inference)\n",
    "        trace = approx.sample(draws=500)\n",
    "        elapsed = time.time() - tstart    \n",
    "        logging.info('Complete BMF sampling in %d seconds' % int(elapsed))\n",
    "        \n",
    "    with bmf:#evaluation\n",
    "        testset = getTestdata()\n",
    "        ppc = pm.sample_posterior_predictive(trace, progressbar=True)\n",
    "        nR = np.mean(ppc['nR'],0)#three dims, calcuate the mean with the first dim for posterior\n",
    "        hits = []\n",
    "        ndcgs = []\n",
    "        prev_u = testset[0][0]\n",
    "        pos_i = testset[0][1]\n",
    "        scorelist = []\n",
    "        for u, i in testset:\n",
    "            if prev_u == u:\n",
    "                scorelist.append([i,nR[u,i]])\n",
    "            else:\n",
    "                map_item_score = {}\n",
    "                for item, rate in scorelist: #turn dict\n",
    "                    map_item_score[item] = rate\n",
    "                ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)#default Topn=10\n",
    "                hr = getHitRatio(ranklist, pos_i)\n",
    "                hits.append(hr)\n",
    "                ndcg = getNDCG(ranklist, pos_i)\n",
    "                ndcgs.append(ndcg)\n",
    "                #next user\n",
    "                scorelist = []\n",
    "                prev_u = u\n",
    "                pos_i = i\n",
    "                scorelist.append([i,nR[u,i]])\n",
    "        hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "        print(\"HR@10: {}, NDCG@10: {}, At K {}\".format(hitratio, ndcg, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -7.7694e+08, ||grad|| = 1.0495e+07: 100%|██████████| 9/9 [00:00<00:00, 41.16it/s]   \n",
      "Only 100 samples in chain.\n",
      "Multiprocess sampling (2 chains in 8 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [Q]\n",
      ">Metropolis: [P]\n",
      "Sampling 2 chains: 100%|██████████| 1200/1200 [00:04<00:00, 299.73draws/s]\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "  6%|▌         | 11/200 [00:00<00:01, 102.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 11, 698)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 86.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 11, 698)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵分解R=PQ，推荐概率模型MCMC采样-直接矩阵采样\n",
    "import theano\n",
    "import pymc3 as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import theano.tensor as tt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#1.数据集处理\n",
    "#http://files.grouplens.org/datasets/movielens/ml-20m-README.html\n",
    "#the following format of file ratings.csv: userId,movieId,rating,timestamp\n",
    "#The lines within this file are ordered first by userId, then, within user, by movieId.\n",
    "#Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\n",
    "#Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "data = pd.read_csv(\"/data/fjsdata/BayesianRS/ml-20m/ratings.csv\",sep=',',low_memory=False,iterator =True)\n",
    "data = data.get_chunk(1000)\n",
    "#将userId和movieId全部标准编号\n",
    "le = LabelEncoder()\n",
    "data = data.apply(le.fit_transform)\n",
    "#2.构建U-I矩阵\n",
    "uNum = len(data['userId'].unique())#统计用户数\n",
    "iNum = len(data['movieId'].unique())#统计电影数\n",
    "UI = np.zeros((uNum, iNum))#转成R矩阵，非常稀疏\n",
    "for index, row in data.iterrows(): # 获取每行的值\n",
    "    UI[int(row['userId'])][int(row['movieId'])] = row['rating']\n",
    "#2.构建概率模型\n",
    "#概率模型参数设置\n",
    "mean= data['rating'].max()/2 #正态分布的均值和方差\n",
    "k = 100 #隐因子数\n",
    "Y_output = theano.shared(UI)#转numpy array\n",
    "with pm.Model() as BMF_model:\n",
    "    # Creating the model\n",
    "    P = pm.Normal('P', mu=mean, sd=mean, shape=(uNum,k))\n",
    "    Q = pm.Normal('Q', mu=mean, sd=mean, shape=(k,iNum))\n",
    "    R = pm.Deterministic('R', tt.dot(P,Q))\n",
    "    Y = pm.Normal('Y',mu=R, sd=mean, observed=Y_output)\n",
    "#3.后验分布计算  \n",
    "with BMF_model:        \n",
    "    start=pm.find_MAP()  # 参数初猜\n",
    "    #二值变量：指定 BinaryMetropolis  离散变量：指定 Metropolis  连续变量：指定 NUTS\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(100,start=start,step=step,chains=2,cores=8)\n",
    "\n",
    "print (trace['R'].shape) #直接用于推荐\n",
    "with BMF_model:\n",
    "    ppc = pm.sample_posterior_predictive(trace, progressbar=True)\n",
    "print (ppc['Y'].shape) #直接用于推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -2,280.5, ||grad|| = 0: 100%|██████████| 2/2 [00:00<00:00, 70.19it/s]\n",
      "Only 100 samples in chain.\n",
      "Multiprocess sampling (2 chains in 8 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [Q]\n",
      ">Metropolis: [P]\n",
      "Sampling 2 chains: 100%|██████████| 1200/1200 [00:03<00:00, 365.28draws/s]\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "100%|██████████| 200/200 [00:00<00:00, 2457.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "RMSE：0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵分解R=PQ，推荐概率模型MCMC采样-似然函数是Bernoulli\n",
    "import theano\n",
    "import pymc3 as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import theano.tensor as tt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#1.数据集处理\n",
    "#http://files.grouplens.org/datasets/movielens/ml-20m-README.html\n",
    "#the following format of file ratings.csv: userId,movieId,rating,timestamp\n",
    "#The lines within this file are ordered first by userId, then, within user, by movieId.\n",
    "#Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\n",
    "#Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "data = pd.read_csv(\"/data/fjsdata/BayesianRS/ml-20m/ratings.csv\",sep=',',low_memory=False,iterator =True)\n",
    "data = data.get_chunk(100)\n",
    "#将userId和movieId全部标准编号\n",
    "le = LabelEncoder()\n",
    "data = data.apply(le.fit_transform)\n",
    "data['rating'] = 1\n",
    "#抽样10%比例测试\n",
    "test = data.sample(frac=0.1)\n",
    "#2.构建概率模型\n",
    "uNum = len(data['userId'].unique())#统计用户数\n",
    "iNum = len(data['movieId'].unique())#统计电影数\n",
    "mean= data['rating'].max()/2 #正态分布的均值和方差\n",
    "k = 100 #隐因子数\n",
    "X_input = theano.shared(data[['userId','movieId']].values)#转numpy array\n",
    "Y_output = theano.shared(data['rating'].values)#转numpy array\n",
    "with pm.Model() as BMF_model:\n",
    "    # Creating the model\n",
    "    P = pm.Normal('P', mu=mean, sd=mean, shape=(uNum,k))\n",
    "    Q = pm.Normal('Q', mu=mean, sd=mean, shape=(k,iNum))\n",
    "    R = tt.dot(P,Q)\n",
    "    rY = []\n",
    "    for row in X_input.get_value(): # 获取每行的值\n",
    "        rr = R[int(row[0])][int(row[1])]#userId=0,movieId=1\n",
    "        rY.append(rr)\n",
    "    rY = pm.Deterministic('rY',pm.math.sigmoid(rY))\n",
    "    Y = pm.Bernoulli('Y', rY, observed=Y_output.get_value())\n",
    "#3.后验分布计算  \n",
    "with BMF_model:        \n",
    "    start=pm.find_MAP()  # 参数初猜\n",
    "    #二值变量：指定 BinaryMetropolis  离散变量：指定 Metropolis  连续变量：指定 NUTS\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(100,start=start,step=step,chains=2,cores=8)\n",
    "    \n",
    "#4.后验预测  \n",
    "#X_input.set_value(test[['userId','movieId']].values)#转numpy array\n",
    "#Y_output.set_value(test['rating'].values)\n",
    "with BMF_model:\n",
    "    ppc = pm.sample_posterior_predictive(trace)\n",
    "    pred = ppc['Y'].mean(axis=0)\n",
    "    print(pred)\n",
    "    \n",
    "print ('RMSE：%f'% mean_squared_error(Y_output.get_value(),pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
